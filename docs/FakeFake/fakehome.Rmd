---
title: "BREAKING NEWS: FBI Says They Found 'Man Child' In The Woods!"
description: |
  If you clicked on this link, it means that my project was a success
site: distill::distill_website
---
## Introduction
Welcome to my very scientific analysis of fake news titles, as I go on a quest to create fake fake news. This investigation follows my journey of  analyzing the length of news article titles and their subjects to create a fake news article of my own. If you wish to see the process, scroll down. If you wish to see the news article, (title was created using data, article was written by a professional journalist that just happens to have the same name), please click [here](NewHorkTimes.html)

# Goals 
Discover how to make the optimal fake news title, or basically, what makes a fake news article good?

Checklist:

1. How long are the titles? How short/long do they need to be to capture your attention?  
2. What words do they use? What topics do they talk about? 

By analyzing a sample of ~7900 headlines, I will attempt to answer these questions. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) #loading libraries
library(tidyverse)
library(tidyr)
library(dplyr)
library(rmarkdown)
library(knitr)
library(plotly)
```

### [Data](https://github.com/BuzzFeedNews/2018-12-fake-news-top-50)
Here is a short sample of data if you want to scroll through, sorted by the amount of Facebook likes they garnered. 


```{r, table}
titledata <- read.csv("newstitleint.csv") #reading csv
paged_table(titledata) %>% #displaying as table 
 mutate_at(vars(fb_engagement), #makes column a int for graphs
            as.integer)
 
```
<div> 
<hr>
</hr>
</div> 

## Breaking Down the Data
# Investigation 1: Outsmarting Our Short Attention Span

First step of our journey into creating our own fake news title is figuring out the the length of the title, which is VERY IMPORTANT. If it's too short, you won't be able to clickbait people into the article, but if it's too long, people won't even read it, which is not ideal. 

First, we calculate how many characters are in each header! Here's a small sample of some of the shortest titles, and how effective they were for getting Facebook likes: 

```{r, calculating character length}
title_length_data <- titledata %>% 
  select(title, fb_engagement) %>%
  drop_na() %>% #dropping na values
  mutate(title_length = str_length(title))  %>%  #finding length of string
  group_by(title_length) %>% 
  arrange(title_length) #arranging from shortest title to longest
```
```{r, table 2 length}
paged_table(title_length_data) #displaying data on table

```
<div> 
OH NO NOT LARRY THE CAT :(((( 
</div>
Anyways, let's get a better representation of this data, shall we? 

```{r, ggplot}
plotlygraph <- ggplot(title_length_data, mapping = aes(x = title_length, y = fb_engagement, color = fb_engagement, text = paste("Title:", title)))+ 
  geom_point(alpha = 0.5)+ #transparency 
  scale_color_gradient(low = "red", #gradient legend
                       high = "blue")+
labs(title = "Correlation between Title Length and Popularity on Facebook", subtitle = "Guess people like 40-75 character titles :)", 
     x = "Length of Title (Characters)", y = "Amount of Facebook Likes", color = "Facebook Likes", 
     caption = "Source: Buzzfeed News 2018")
```
```{r, display ggplotly}
ggplotly(plotlygraph, tooltip = c("text", "x")) #adjusting ggplotly labels
```

By looking at the graph, it is clear the length of the news articles should be between 47-84, as those seem to perform the best.This data is supported by the fact that mean length of titles is around 67 characters. I mean, usually if everyone's doing it... you should do it too right? 

Regardless, that settles it! The ideal fake news title must be around 67 characters. 

<div> 
<hr> 
</hr>
</div> 


# Investigation 2 - The Almighty Power of Words 
### Determining the Most Popular Words

After deciding how long our title is going to be, we gotta decide what it's actually going to be about!
After a long, and extremely tiring process of going through thousands of articles, these are the most popular words! 

<div> </div> 
I know what you're thinking, this is clearly the MOST fascinating graph you have ever seen.

```{r, first graph}
titledata %>% #splitting title data again
  select(title, category) %>%
  mutate(title = strsplit(as.character(title), " ")) %>% #splitting by space to seperate each word
  unnest(title) %>% 
  group_by(title) %>% 
  summarize(total = n()) %>% #finding how many other times the word has been said
  arrange(desc(total)) %>% 
  slice(1:10) %>% #Only showing 10 on graph

ggplot(mapping = aes(x = reorder(title, total), y = total))+
  geom_col(fill = "darkseagreen3")+
  theme_classic()+
  coord_flip()+
labs(title = "Most Common Words in Fake News Headlines", 
     subtitle = "Wow! What a diverse range of words, could totally make a headline out of it!", y = "Amount of Times it has Appeared in a Headline", x = "Word", caption = "Source: BuzzFeed News 2018")
```
<div>
Hmm.... Let's  clean this data up by removing duplicates, punctuation, and prepositions from it! That'd give us a better idea of what people enjoy to read about, and allow us to find the best subject to center our article around!
</div>

```{r, politic graph}
titledata <- read.csv("newstitle1.csv") #reentering data
removedata <- titledata %>%
  select(title, category) %>%
  mutate(title = strsplit(as.character(title), " ")) %>%
  unnest(title) %>%
  group_by(title) %>%
  summarize(total = n()) %>%
  arrange(desc(total)) %>%
  slice(1:50)

newdata <- removedata[c(4, 15, 16, 17, 21, 25, 28, 29, 30, 37),] #removing all preopositions
ggplot(newdata, mapping = aes(x = reorder(title, total), y = total))+
  geom_col(fill = "darkseagreen3")+
  theme_classic()+
  coord_flip()+
labs(title = "Most Common Words in Fake News Headlines (Edited)",
     subtitle = "Painfully obvious what year this is from", y = "Amount of Times it has Appeared in a Headline", x = "Word", caption = "Source: BuzzFeed News 2018")
```
<div>
Oh, this isn't fun. This just SCREAMS 2018. Let's get away from all the specific events that happened this year (mainly the US election) and see what other interesting stuff we can find, so that it's believable any time of the year

</div> 

```{r, final graph}
titledata <- read.csv("newstitle1.csv")
removedata <- titledata %>%
  select(title, category) %>%
  mutate(title = strsplit(as.character(title), " ")) %>%
  unnest(title) %>%
  group_by(title) %>% #repeat
  summarize(total = n()) %>%
  arrange(desc(total)) %>%
  slice(1:50)

newdata2 <- removedata[c(16, 17, 25, 28, 29, 33, 35, 44, 45, 47),] #removing politics 
ggplot(newdata2, mapping = aes(x = reorder(title, total), y = total))+
  geom_col(fill = "darkseagreen3")+
  theme_classic()+
  coord_flip()+
labs(title = "Most Common Words in Fake News Headlines (Non-Politics)",
     subtitle = "Missing Children Cases on the Rise?", y = "Amount of Times it has Appeared in a Headline", x = "Word", caption = "Source: BuzzFeed News 2018")
```

<div>
Alright.... now we can work with this data. Considering out character limit from before, and taking the subjects that were taken from headlines.... the best fake fake news article title (proven using data) is: 

# BREAKING NEWS: FBI says they found 'Man Child' in the woods!
</div> 